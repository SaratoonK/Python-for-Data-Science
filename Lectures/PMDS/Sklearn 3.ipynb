{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sklearn Workshop 3: Car Price Prediction (Regression)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: ETL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/car.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>year</th>\n",
       "      <th>selling_price</th>\n",
       "      <th>km_driven</th>\n",
       "      <th>fuel</th>\n",
       "      <th>seller_type</th>\n",
       "      <th>transmission</th>\n",
       "      <th>owner</th>\n",
       "      <th>mileage</th>\n",
       "      <th>engine</th>\n",
       "      <th>max_power</th>\n",
       "      <th>torque</th>\n",
       "      <th>seats</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Maruti Swift Dzire VDI</td>\n",
       "      <td>2014</td>\n",
       "      <td>450000</td>\n",
       "      <td>145500</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Manual</td>\n",
       "      <td>First Owner</td>\n",
       "      <td>23.4 kmpl</td>\n",
       "      <td>1248 CC</td>\n",
       "      <td>74 bhp</td>\n",
       "      <td>190Nm@ 2000rpm</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Skoda Rapid 1.5 TDI Ambition</td>\n",
       "      <td>2014</td>\n",
       "      <td>370000</td>\n",
       "      <td>120000</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Manual</td>\n",
       "      <td>Second Owner</td>\n",
       "      <td>21.14 kmpl</td>\n",
       "      <td>1498 CC</td>\n",
       "      <td>103.52 bhp</td>\n",
       "      <td>250Nm@ 1500-2500rpm</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Honda City 2017-2020 EXi</td>\n",
       "      <td>2006</td>\n",
       "      <td>158000</td>\n",
       "      <td>140000</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Manual</td>\n",
       "      <td>Third Owner</td>\n",
       "      <td>17.7 kmpl</td>\n",
       "      <td>1497 CC</td>\n",
       "      <td>78 bhp</td>\n",
       "      <td>12.7@ 2,700(kgm@ rpm)</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hyundai i20 Sportz Diesel</td>\n",
       "      <td>2010</td>\n",
       "      <td>225000</td>\n",
       "      <td>127000</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Manual</td>\n",
       "      <td>First Owner</td>\n",
       "      <td>23.0 kmpl</td>\n",
       "      <td>1396 CC</td>\n",
       "      <td>90 bhp</td>\n",
       "      <td>22.4 kgm at 1750-2750rpm</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Maruti Swift VXI BSIII</td>\n",
       "      <td>2007</td>\n",
       "      <td>130000</td>\n",
       "      <td>120000</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Manual</td>\n",
       "      <td>First Owner</td>\n",
       "      <td>16.1 kmpl</td>\n",
       "      <td>1298 CC</td>\n",
       "      <td>88.2 bhp</td>\n",
       "      <td>11.5@ 4,500(kgm@ rpm)</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           name  year  selling_price  km_driven    fuel  \\\n",
       "0        Maruti Swift Dzire VDI  2014         450000     145500  Diesel   \n",
       "1  Skoda Rapid 1.5 TDI Ambition  2014         370000     120000  Diesel   \n",
       "2      Honda City 2017-2020 EXi  2006         158000     140000  Petrol   \n",
       "3     Hyundai i20 Sportz Diesel  2010         225000     127000  Diesel   \n",
       "4        Maruti Swift VXI BSIII  2007         130000     120000  Petrol   \n",
       "\n",
       "  seller_type transmission         owner     mileage   engine   max_power  \\\n",
       "0  Individual       Manual   First Owner   23.4 kmpl  1248 CC      74 bhp   \n",
       "1  Individual       Manual  Second Owner  21.14 kmpl  1498 CC  103.52 bhp   \n",
       "2  Individual       Manual   Third Owner   17.7 kmpl  1497 CC      78 bhp   \n",
       "3  Individual       Manual   First Owner   23.0 kmpl  1396 CC      90 bhp   \n",
       "4  Individual       Manual   First Owner   16.1 kmpl  1298 CC    88.2 bhp   \n",
       "\n",
       "                     torque  seats  \n",
       "0            190Nm@ 2000rpm    5.0  \n",
       "1       250Nm@ 1500-2500rpm    5.0  \n",
       "2     12.7@ 2,700(kgm@ rpm)    5.0  \n",
       "3  22.4 kgm at 1750-2750rpm    5.0  \n",
       "4     11.5@ 4,500(kgm@ rpm)    5.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.describe()  #no missing values, seems like....\n",
    "# df.dtypes\n",
    "# df['selling_price'].value_counts()  #no need to check imbalanced because this is a regression problem\n",
    "df.head()\n",
    "\n",
    "#?Note: We don't need the year.....because year can be linearly correlated with price but with no meaning due to inflation anyway\n",
    "#?      Some missing values in seats?\n",
    "#?      Wow, so many object.....we need encoding :-(\n",
    "#?      We don't need name too....because name won't be related to price.....\n",
    "#?      Oh...we have to fix the mileage and remove kmpl....\n",
    "#?      We have to remove CC in engine\n",
    "#?      We have to remove bhp\n",
    "#?      Based on domain expert, we shall drop torque (ok?)\n",
    "\n",
    "#selling_price:  our target\n",
    "\n",
    "#continuous: km_driven, mileage, engine, max_power, torque\n",
    "#discrete:   seats, fuel, seller_type, transmission, owner, \n",
    "\n",
    "#seats can be both continuous or discrete...up to you"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1  Fix the columns (extract the meaning from the text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "First Owner             5289\n",
       "Second Owner            2105\n",
       "Third Owner              555\n",
       "Fourth & Above Owner     174\n",
       "Test Drive Car             5\n",
       "Name: owner, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['owner'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['owner'] = df['owner'].map({'First Owner': 1, 'Second Owner': 2, 'Third Owner': 3, 'Fourth & Above Owner': 4, 'Test Drive Car': 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    5289\n",
       "2    2105\n",
       "3     555\n",
       "4     174\n",
       "5       5\n",
       "Name: owner, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['owner'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Diesel    4402\n",
       "Petrol    3631\n",
       "CNG         57\n",
       "LPG         38\n",
       "Name: fuel, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.fuel.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's delete all rows with CNG and LPG\n",
    "condCNG = df.fuel == 'CNG'\n",
    "condLPG = df.fuel == 'LPG'\n",
    "condCNG_index = np.where(condCNG | condLPG)  #retrieve the index\n",
    "df.drop(condCNG_index[0], axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Diesel    4402\n",
       "Petrol    3631\n",
       "Name: fuel, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.fuel.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.mileage = df.mileage.str.split(\" \").str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.engine = df.engine.str.split(\" \").str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.max_power = df.max_power.str.split(\" \").str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'name': 'brand'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.brand = df.brand.str.split(\" \").str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>year</th>\n",
       "      <th>selling_price</th>\n",
       "      <th>km_driven</th>\n",
       "      <th>fuel</th>\n",
       "      <th>seller_type</th>\n",
       "      <th>transmission</th>\n",
       "      <th>owner</th>\n",
       "      <th>mileage</th>\n",
       "      <th>engine</th>\n",
       "      <th>max_power</th>\n",
       "      <th>torque</th>\n",
       "      <th>seats</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Maruti</td>\n",
       "      <td>2014</td>\n",
       "      <td>450000</td>\n",
       "      <td>145500</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Manual</td>\n",
       "      <td>1</td>\n",
       "      <td>23.4</td>\n",
       "      <td>1248</td>\n",
       "      <td>74</td>\n",
       "      <td>190Nm@ 2000rpm</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Skoda</td>\n",
       "      <td>2014</td>\n",
       "      <td>370000</td>\n",
       "      <td>120000</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Manual</td>\n",
       "      <td>2</td>\n",
       "      <td>21.14</td>\n",
       "      <td>1498</td>\n",
       "      <td>103.52</td>\n",
       "      <td>250Nm@ 1500-2500rpm</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Honda</td>\n",
       "      <td>2006</td>\n",
       "      <td>158000</td>\n",
       "      <td>140000</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Manual</td>\n",
       "      <td>3</td>\n",
       "      <td>17.7</td>\n",
       "      <td>1497</td>\n",
       "      <td>78</td>\n",
       "      <td>12.7@ 2,700(kgm@ rpm)</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hyundai</td>\n",
       "      <td>2010</td>\n",
       "      <td>225000</td>\n",
       "      <td>127000</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Manual</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1396</td>\n",
       "      <td>90</td>\n",
       "      <td>22.4 kgm at 1750-2750rpm</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Maruti</td>\n",
       "      <td>2007</td>\n",
       "      <td>130000</td>\n",
       "      <td>120000</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Manual</td>\n",
       "      <td>1</td>\n",
       "      <td>16.1</td>\n",
       "      <td>1298</td>\n",
       "      <td>88.2</td>\n",
       "      <td>11.5@ 4,500(kgm@ rpm)</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     brand  year  selling_price  km_driven    fuel seller_type transmission  \\\n",
       "0   Maruti  2014         450000     145500  Diesel  Individual       Manual   \n",
       "1    Skoda  2014         370000     120000  Diesel  Individual       Manual   \n",
       "2    Honda  2006         158000     140000  Petrol  Individual       Manual   \n",
       "3  Hyundai  2010         225000     127000  Diesel  Individual       Manual   \n",
       "4   Maruti  2007         130000     120000  Petrol  Individual       Manual   \n",
       "\n",
       "   owner mileage engine max_power                    torque  seats  \n",
       "0      1    23.4   1248        74            190Nm@ 2000rpm    5.0  \n",
       "1      2   21.14   1498    103.52       250Nm@ 1500-2500rpm    5.0  \n",
       "2      3    17.7   1497        78     12.7@ 2,700(kgm@ rpm)    5.0  \n",
       "3      1    23.0   1396        90  22.4 kgm at 1750-2750rpm    5.0  \n",
       "4      1    16.1   1298      88.2     11.5@ 4,500(kgm@ rpm)    5.0  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the categorical columns\n",
    "# for col in dis_df.columns:\n",
    "#     sns.countplot(x = df['price_range'], hue=df[col])  #use count because \"counting\" the categories\n",
    "#     plt.show()\n",
    "\n",
    "#? We learn that:  nothing in the categorical column stands out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in con_df.columns:\n",
    "#     sns.barplot(x = df['price_range'], y=df[col])  #use barplot/boxplot for numbers\n",
    "#     plt.show()\n",
    "    \n",
    "#? We learn that (very strong):  battery_power, px_height, px_width, ram\n",
    "#?               (some trend) :  int_memory, \n",
    "#? Hmm...maybe let the corr() confirms out for us....."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(20, 10))\n",
    "# sns.heatmap(df.corr(), annot=True)\n",
    "\n",
    "#? Things with around >0.4-0.5 correlation with price_range:  ram\n",
    "#? Things with around >0.1     correlation with price_range:  battery_power, px_height, px_width\n",
    "\n",
    "#? So in conclusion, we will use ram, battery_power, px_height, px_width\n",
    "#? Note: you can use all features, but it can increase your model complexity.....unnecessarily"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[ ['ram', 'battery_power', 'px_height', 'px_width'] ]\n",
    "y = df['price_range']\n",
    "\n",
    "assert X.ndim == 2\n",
    "assert y.ndim == 1\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=999)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1 Filling missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#double check that no missing values....\n",
    "# X_train.isna().sum() \n",
    "# X_test.isna().sum() \n",
    "# y_train.isna().sum() \n",
    "# y_test.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.2 Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all our values do not need to encode, because they are all numeric :-)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.3 Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "\n",
    "X_train = sc.fit_transform(X_train) #we scale all features, because all our features are continuous\n",
    "X_test  = sc.transform(X_test)\n",
    "\n",
    "#we did not transform y_test or y_train\n",
    "\n",
    "#after standardize, the mean should be zero; the std should be 1\n",
    "for feature in range(X_train.shape[1]):\n",
    "    assert np.isclose(X_train[:, feature].mean(), 0)  #cannot == 0 because is near 0 not 0\n",
    "    assert np.isclose(X_train[:, feature].std(),  1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "#models\n",
    "lr, nb, sv, rf, gb = LogisticRegression(), GaussianNB(), SVC(), RandomForestClassifier(), GradientBoostingClassifier()\n",
    "\n",
    "models = [lr, nb, sv, rf, gb]\n",
    "names  = [\"lr\", \"nb\", \"sv\", \"rf\", \"gb\"]\n",
    "\n",
    "for idx, model in enumerate(models):\n",
    "    score = cross_val_score(model, X_train, y_train, n_jobs=-1) #no need cv and scoring because their default is ok in our case\n",
    "    print(f\"{names[idx]} - Mean: {score.mean()}; Std: {score.std()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "model = LogisticRegression(random_state=999)  #<----this is the model I choose, after cross validation\n",
    "\n",
    "param_grid = dict()\n",
    "param_grid['solver'] = ['newton-cg', 'lbfgs', 'liblinear']  #this is listed in the sklearn website\n",
    "#add more parameters here\n",
    "#param_grid[parameter] = list of parameters to search\n",
    "\n",
    "#refit means it will pick the best model, and fit again, so it means grid is already the best model after this line\n",
    "grid = GridSearchCV(model, param_grid, refit=True, return_train_score=True)\n",
    "#scoring = f1, recall, precision, accuracy\n",
    "\n",
    "#fit the grid, which will basically do cross validation across all combinatiosn, here we only have 3 comb\n",
    "grid.fit(X_train, y_train)  #remember to use only training set here....\n",
    "\n",
    "#print the best parameters and accuracy\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)\n",
    "# print(grid.cv_results_)   #hide this for aesthetic\n",
    "\n",
    "#this score is cross-validation score, basically the accuracy/precision/etc on the validation set\n",
    "\n",
    "#?Note:  our train score is around 0.95, 0.95, 0.82;  the val score is 0.95, 0.96, 0.82\n",
    "#?       so no overfitting....because they are close\n",
    "#?Note:  if we have overfitting, we need to check many things, e.g., \n",
    "#?       - choose simpler model\n",
    "#?       - help the model choose better features\n",
    "#?       - collect more high quality data, and more data....\n",
    "#?       - or maybe your data has no pattern!! :-) the model is just learning pattern of noises......"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y = grid.predict(X_test)\n",
    "\n",
    "#if your website needs probability, you can use \n",
    "#proba or log_proba are same, log_proba just make the value more scaled....\n",
    "#?  Note:  some algorithm has no predict_proba() so please check\n",
    "    #pred_y_prob = grid.predict_proba(X_test)\n",
    "#or\n",
    "    #pred_y_logprob = grid.predict_log_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "print(classification_report(y_test, pred_y))\n",
    "#? Note:  we can use all four metrics to understand\n",
    "#? Accuracy:  0.95 - we can use it because our data is balanced\n",
    "#? Precision: 0.95 - look at this metric if you want to prioritize lowering FP\n",
    "#? Recall:    0.95 - look at this metirc if you want to prioritize lowering FN\n",
    "#? F1-score:  0.95 - look at this metric if you want to prioritize lowering both FP and FN\n",
    "\n",
    "#?macro-avg average all classes\n",
    "#?weighted-avg average all classes * their fraction of sample sizes\n",
    "\n",
    "#?if your data is balanced, both avg will be the same (anyway)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm  = confusion_matrix(y_test, pred_y)\n",
    "cmp = ConfusionMatrixDisplay(cm, display_labels=[0, 1, 2, 3])\n",
    "\n",
    "cmp.plot()\n",
    "\n",
    "#? Note:  0 is often confused as 1\n",
    "#?        1 is confused as 2\n",
    "#?        2 is confused as 3\n",
    "#?  This makes sense because close price range may be easily confused.......i guess (i don't know)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's check which sample like to get wrong, especially \"0 is often confused as 1\"\n",
    "conda = pred_y == 0\n",
    "condb = y_test == 1\n",
    "\n",
    "X_test[conda & condb]  \n",
    "#so i will leave at that....but if you are the domain expert, you can check here....\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_estimator_.coef_ #(n_classes, n_features)\n",
    "#n_classes means 0, 1, 2, 3\n",
    "#if we have only two classes, it will be (1, n_features), because it can 0 or 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = pd.DataFrame(['ram', 'battery_power', 'px_height', 'px_width'], \n",
    "                                  columns=['features'])\n",
    "feature_importance[\"0\"] = grid.best_estimator_.coef_[0]\n",
    "feature_importance[\"1\"] = grid.best_estimator_.coef_[1]\n",
    "feature_importance[\"2\"] = grid.best_estimator_.coef_[2]\n",
    "feature_importance[\"3\"] = grid.best_estimator_.coef_[3]\n",
    "\n",
    "for _class in ['0', '1', '2', '3']:  \n",
    "    feature_importance = feature_importance.sort_values(by = [_class], ascending=True)\n",
    "    feature_importance.plot.barh(x='features', y=_class)\n",
    "    plt.show()\n",
    "    \n",
    "#? What we learn:\n",
    "#? Class 0:  Ram is most important;  Ram negatively impact the price_range of 0\n",
    "#? Class 1:  Ram is most important;  Ram negatively impact the price_range of 1\n",
    "#? Class 2:  Ram is most important;  Ram positively impact the price_range of 2\n",
    "#? Class 3:  Ram is most important;  Ram positively impact the price_range of 3\n",
    "\n",
    "#? Overall, all importances point out that ram > battery_power > px_width > px_height"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Saving the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#please help me save the model here\n",
    "import pickle\n",
    "\n",
    "# save the model\n",
    "filename = 'mobile_price.pkl' # pkl does not matter, you can do .everything\n",
    "pickle.dump(grid, open(filename,'wb'))\n",
    "\n",
    "# Load the model\n",
    "loaded_grid=pickle.load(open(filename,'rb'))\n",
    "\n",
    "# try predict X_test\n",
    "loaded_grid.predict(X_test)\n",
    "\n",
    "# if you have new data, then you fit again....but using loaded_grid\n",
    "# which is a process of training more.....once you have more data....\n",
    "\n",
    "# or another way is\n",
    "# put all the dataset together, and train like it is new\n",
    "    #this is possible ONLY if your dataset is not that big......\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For real world prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for actual use? to predict some future data.....\n",
    "some_data = np.array([ [1, 2, 3, 4], [2, 3, 4, 5] ])\n",
    "\n",
    "#standardize\n",
    "some_data = sc.transform(some_data)\n",
    "\n",
    "#predict\n",
    "pred = grid.predict(some_data)\n",
    "\n",
    "pred #both samples have price_range of 3 (predicted, NOT actual, because we don't have actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock = np.array([ [1, 1.01, 0.99, 0.80, 0.5, 0.9, 1.1, 1.2]])\n",
    "\n",
    "#window size = 3\n",
    "#predict the next 2 days\n",
    "\n",
    "#X_1 = 1, 1.01, 0.99\n",
    "#y_1 = 0.80, 0.5\n",
    "\n",
    "#X_2 = 1.01, 0.99, 0.80\n",
    "#y_2 = 0.5, 0.9\n",
    "\n",
    "#X_3 = 0.99, 0.80, 0.5\n",
    "#y_3 = 0.9, 1.1\n",
    "\n",
    "#so on.....\n",
    "#this will be your training set!!\n",
    "\n",
    "# for in range(, , window_size):\n",
    "#     X = \n",
    "#     y = "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.6 ('teaching_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "becc4c8e5ad229b2591d820334d85e3db0111492344629bf57f272470dce75a5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
