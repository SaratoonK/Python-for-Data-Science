{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where are we now\n",
    "1. Python - general problem solving\n",
    "2. Data Science - NumPy, Pandas, Sklearn, Matplotlib \n",
    "3. ML from Scratch - Intuition (so for those who want to further advance....)\n",
    "4. Signal Processing - Energy, Telecommunciations, Biosignals, Time Series\n",
    "5. Deep Learning - PyTorch\n",
    "   1. One of the most popular DL framework (against TensorFlow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning vs. Machine Learning\n",
    "\n",
    "Good News\n",
    "- Deep Learning can automatically feature engineer / feature selection\n",
    "- Deep Learning can benefit from huge amount of data, while Machine Learning cannot\n",
    "  - 100 samples vs 1000 samples, ML will get the same accuracy\n",
    "  - But DL will see increased accuracy\n",
    "- Deep Learning is basically stacking a lot of linear regression together\n",
    "  - DL can learn very complex patterns\n",
    "  - DL is perfect for (1) images, (2) text, (3) signal (very random)\n",
    "\n",
    "Bad News\n",
    "- Deep Learning sucks with small data (vs. Machine Learning) - 5000++ samples\n",
    "- For Tabular Data, Deep Learning will ALMOST ALWAYS LOSE TO gradient boosting (or its variants)\n",
    "  - Gradient Boosting is basically decision trees stacking after one another....\n",
    "  - For most competition, XGBoost and LightGBM are always the winners for tabular data\n",
    "  - If you work in a company, mostly they use tabular data, then you should look for gradient boosting types.... \n",
    "- Deep Learning has NO feature importance; so it's mostly blackbox....(Explanable AI)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
